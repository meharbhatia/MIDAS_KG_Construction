## Updates are here ##

Regarding submissions:

- ```new_6.csv``` is created by using spacyNER+rulebased , dataset input was cleaned dataset, removed isolated nodes (even with isolated nodes number of tupples were more or less same). Also when the error came, I replaced the new line character (```\n```) with ```<space>```.

- ```new_7.csv``` has same parameter as that of ```new_6``` just the difference is, it has been run on ```g050_Coref_Dataset.csv```

- ```new_8.csv``` has same parameter as that of ```new_6``` just the difference is, it has been run on ```g055_Coref_Dataset.csv```

- ```new_9.csv``` is the first csv file which is generated by using flair. Dataset used was g50 coref dataset. SpacyNER is not implemented and CD JJ POS tags are not removed from this. It gave a score of 12.

- ```news_10.csv``` is same as new_9 just the difference is dataset. It used cleaned dataset.

- ```trial_submission_coref.csv``` includes the triples when redundant triples have been removed from coref_triplets.csv. Triples which do not have (NN, NNS, NNP, CD) in any of the node. Gave a score - 11.82.

- ```trial_submission.csv``` includes the triples when redundant triples have been removed from new_7.csv. Triples which do not have (NN, NNS, NNP, CD) in any of the node. Gave a score - 11.78 .

- ``` wiki_file_trial.csv``` includes the triples after passing through domain based test via Wikipedia2vec. Gave a score - 11.77. 
